{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clean_reddit_posts.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEAVPfzjCNTS",
        "colab_type": "text"
      },
      "source": [
        "## Clean Reddit Posts.\n",
        "In this notebook I will clean the reddit posts. This is essential step in Machine Learning and Deep Learning. The following steps were taken to clean the text.\n",
        "* Remove HTML tags, if any, in the text.\n",
        "* Remove accented characters.\n",
        "* Expand the contractions.\n",
        "* Remove special characters.\n",
        "* Remove common words like Hi, Hey, Hello etc.  \n",
        "I am not removing stopwords as they will be handled in individual notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPmiR01P0uvY",
        "colab_type": "code",
        "outputId": "9bc93f70-3d23-4750-a219-e93852cdfaa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLkk4wfLbdd9",
        "colab_type": "code",
        "outputId": "cdf4a57f-4ef5-49c6-9979-38b449e564f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "!pip install textsearch\n",
        "!pip install contractions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting textsearch\n",
            "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
            "Collecting pyahocorasick (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 3.9MB/s \n",
            "\u001b[?25hCollecting Unidecode (from textsearch)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 34.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81702 sha256=015d778793164eaf7bdbf2806ecf64b4e42b043b3b1ad61db3b814d499aae45f\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, Unidecode, textsearch\n",
            "Successfully installed Unidecode-1.1.1 pyahocorasick-1.4.0 textsearch-0.0.17\n",
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/2a/ba0a3812e2a1de2cc4ee0ded0bdb750a7cef1631c13c78a4fc4ab042adec/contractions-0.0.21-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwYjEowt0wVz",
        "colab_type": "code",
        "outputId": "f4b33909-d287-49e1-d343-0d112adb91fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import unicodedata\n",
        "import contractions\n",
        "import spacy\n",
        "import nltk\n",
        "import tqdm\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx6cLbie07E1",
        "colab_type": "code",
        "outputId": "dfbcc8cf-8410-4254-b48c-9fb93637436f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/reddit_posts.csv')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>SubReddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What things about React annoy you the most?</td>\n",
              "      <td>Can be anything: missing features, boilerplate...</td>\n",
              "      <td>reactjs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tutorial: Building a contacts manager using Vu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having trouble deciding what design pattern sh...</td>\n",
              "      <td>The structure of my project is the following:\\...</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prettier rule for this?</td>\n",
              "      <td>I use Prettier and the auto format on save opt...</td>\n",
              "      <td>reactjs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Conditional Rendering in Vue JS - Beginner Tut...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ... SubReddit\n",
              "0        What things about React annoy you the most?  ...   reactjs\n",
              "1  Tutorial: Building a contacts manager using Vu...  ...     vuejs\n",
              "2  Having trouble deciding what design pattern sh...  ...     vuejs\n",
              "3                            Prettier rule for this?  ...   reactjs\n",
              "4  Conditional Rendering in Vue JS - Beginner Tut...  ...     vuejs\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHL_CAh31MMt",
        "colab_type": "code",
        "outputId": "04089f38-d7b8-4d65-e62d-2ceeb96e6e63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df['Title'] = df['Title'].fillna('missing')\n",
        "df['Body'] = df['Body'].fillna('missing')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>SubReddit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What things about React annoy you the most?</td>\n",
              "      <td>Can be anything: missing features, boilerplate...</td>\n",
              "      <td>reactjs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tutorial: Building a contacts manager using Vu...</td>\n",
              "      <td>missing</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Having trouble deciding what design pattern sh...</td>\n",
              "      <td>The structure of my project is the following:\\...</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Prettier rule for this?</td>\n",
              "      <td>I use Prettier and the auto format on save opt...</td>\n",
              "      <td>reactjs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Conditional Rendering in Vue JS - Beginner Tut...</td>\n",
              "      <td>missing</td>\n",
              "      <td>vuejs</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ... SubReddit\n",
              "0        What things about React annoy you the most?  ...   reactjs\n",
              "1  Tutorial: Building a contacts manager using Vu...  ...     vuejs\n",
              "2  Having trouble deciding what design pattern sh...  ...     vuejs\n",
              "3                            Prettier rule for this?  ...   reactjs\n",
              "4  Conditional Rendering in Vue JS - Beginner Tut...  ...     vuejs\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWdisf3t1fJh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', parse=False, tag=False, entity=False)\n",
        "ps = nltk.porter.PorterStemmer()\n",
        "\n",
        "\n",
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    [s.extract() for s in soup(['iframe', 'script'])]\n",
        "    stripped_text = soup.get_text()\n",
        "    stripped_text = re.sub(r'[\\r|\\n|\\r\\n]+', '\\n', stripped_text)\n",
        "    return stripped_text\n",
        "\n",
        "\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "\n",
        "def expand_contractions(text):\n",
        "    return contractions.fix(text)\n",
        "\n",
        "\n",
        "def spacy_lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "\n",
        "\n",
        "def simple_stemming(text, stemmer=ps):\n",
        "    text = ' '.join([stemmer.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False, stopwords=None):\n",
        "    if not stopwords:\n",
        "        stopwords = nltk.corpus.stopwords.words('english')\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    \n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopwords]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopwords]\n",
        "    \n",
        "    filtered_text = ' '.join(filtered_tokens) \n",
        "    return filtered_text\n",
        "\n",
        "def remove_common_word(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    common_words = ['hey', 'hello', 'hi']\n",
        "    filtered_tokens = [token for token in tokens if token.lower() not in common_words]\n",
        "    filtered_text = ' '.join(filtered_tokens) \n",
        "    return filtered_text\n",
        "\n",
        "def text_pre_processor(text, html_strip=True, accented_char_removal=True, contraction_expansion=True,\n",
        "                       text_lower_case=False, special_char_removal=True, remove_digits=True, stopword_removal=False, \n",
        "                       stopword_list=None, text_stemming=False, text_lemmatization=False, remove_common_words=True):\n",
        "    \n",
        "    #remove urls\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    \n",
        "    # strip HTML\n",
        "    if html_strip:\n",
        "        text = strip_html_tags(text)\n",
        "    \n",
        "    # remove extra newlines (often might be present in really noisy text)\n",
        "    text = text.translate(text.maketrans(\"\\n\\t\\r\", \"   \"))\n",
        "    \n",
        "    \n",
        "    # remove accented characters\n",
        "    if accented_char_removal:\n",
        "        text = remove_accented_chars(text)\n",
        "    \n",
        "    # expand contractions    \n",
        "    if contraction_expansion:\n",
        "        text = expand_contractions(text)\n",
        "        \n",
        "        \n",
        "    # remove special characters and\\or digits    \n",
        "    if special_char_removal:\n",
        "        # insert spaces between special characters to isolate them    \n",
        "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "        text = special_char_pattern.sub(\" \\\\1 \", text)\n",
        "        text = remove_special_characters(text, remove_digits=remove_digits)\n",
        "        \n",
        "         \n",
        "    # lowercase the text    \n",
        "    if text_lower_case:\n",
        "        text = text.lower()\n",
        "        \n",
        "        \n",
        "    # remove stopwords\n",
        "    if stopword_removal:\n",
        "        text = remove_stopwords(text, is_lower_case=text_lower_case, \n",
        "                                stopwords=stopword_list)\n",
        "    if remove_common_words:\n",
        "      text = remove_common_word(text)\n",
        "        \n",
        "    # remove extra whitespace\n",
        "    text = re.sub(' +', ' ', text)\n",
        "    text = text.strip()\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-B8uqWH28x8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Clean_Title'] = df['Title'].apply(text_pre_processor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJHWZhvS3KSQ",
        "colab_type": "code",
        "outputId": "29501220-8f67-417b-f9f6-1d0c4343cdb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(df.loc[700,'Title'])\n",
        "print(df.loc[700,'Clean_Title'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Anyone know how to interpolate a string in VuePress markdown triple backlash code part?\n",
            "Anyone know how to interpolate a string in VuePress markdown triple backlash code part\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gsv5_923cbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Clean_Body'] = df['Body'].apply(text_pre_processor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caxoxlAt4Cm0",
        "colab_type": "code",
        "outputId": "b359d80a-9d15-4417-aabb-ce8417747faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(df.loc[100,'Body'])\n",
        "print('###################################')\n",
        "print(df.loc[100,'Clean_Body'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Simple, I hope, question. I have a small data lookup app I built for a client in Vue that I now need to secure a bit better then it was originally. I setup a simple login using AWS Amplify but when I build for prod my bundle with just the login in it is 3.5mb. is there any way to trim amplify down?\n",
            "###################################\n",
            "Simple I hope question I have a small data lookup app I built for a client in Vue that I now need to secure a bit better then it was originally I setup a simple login using AWS Amplify but when I build for prod my bundle with just the login in it is mb is there any way to trim amplify down\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc7f9krD4Mft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/clean_reddit_posts.csv', index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8H6DnRKEcg_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}